---
title: "Progetto di fondamenti di scienza dei dati"
output: 
  ioslides_presentation:
    incremental: yes
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, message = FALSE, warning = FALSE)
```

## Analisi di libri sulla paeontologia

Libri utilizzati:

- Animals of the past (38013)
- The aincent life history of the earth (14279)
- The story of evolution (1043)
- The chain of life in geological time (36261)

```{r, echo = FALSE}
library(dplyr)
library(readr)
library(tidyr)
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(ggplot2)
library(SnowballC)
library(stringr)
library(scales)
library(ggpubr)
theme_set(theme_pubr())


#funzioni
#formatto i libri dividendo le parole e togliendo le stop words

tidy_book = function(book){
  new_book <- book %>%
  unnest_tokens(word, text) %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>%
  anti_join(stop_words)
  
  return(new_book)
}

#scarico i libri

#book1 = gutenberg_download(38013)
#book2 = gutenberg_download(14279)
#book3 = gutenberg_download(1043)
#book4 = gutenberg_download(36261)

#write_rds(book1, "book1.rds")
#write_rds(book2, "book2.rds")
#write_rds(book3, "book3.rds")
#write_rds(book4, "book4.rds")

book1 <- read_rds("book1.rds")
book2 <- read_rds("book2.rds")
book3 <- read_rds("book3.rds")
book4 <- read_rds("book4.rds")

#visualizzo data frame delle parole + usate per ciascun libro

tidy_book1 <- tidy_book(book1)
tidy_book2 <- tidy_book(book2)
tidy_book3 <- tidy_book(book3)
tidy_book4 <- tidy_book(book4)

#tidy_book1 %>% count(word, sort=TRUE)
#tidy_book2 %>% count(word, sort=TRUE)
#tidy_book3 %>% count(word, sort=TRUE)
#tidy_book4 %>% count(word, sort=TRUE)

#unisco i libri in un unico data frame e li formatto

normal_books <- bind_rows(mutate(book1, book = "animals of the past"),
                          mutate(book2, book = "the aincent life history of the earth"),
                          mutate(book3, book = "the story of evolution"),
                          mutate(book4, book = "the chain of life in geological time"))

normal_books$gutenberg_id <- NULL

books <- tidy_book(normal_books)

#tolgo la parola fig(usata per le figure)/ tutte gli NA/ tutte le parole rimaste con lunghezza <= 2 (unità di misura, ecc.)

books <- books %>%
  filter(word != "fig") %>%
  filter(!is.na(word)) %>%
  filter(str_length(word) > 2)
```

## Parole più usate

```{r, echo = FALSE}
#parole più usate (+ applico il word stemming)

books %>%
  mutate(word = wordStem(word)) %>%
  group_by(book) %>%
  count(word, sort=TRUE) %>%
  top_n(10, n) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, n, book)) %>%
  ggplot(aes(word, n, fill = book)) +
  geom_col(show.legend = FALSE) +
  scale_x_reordered() +
  labs(y = "number of occurences") +
  facet_wrap(~book, scales = "free_y") +
  coord_flip()

```

## Analisi dei bigrammi

```{r, echo = FALSE}
#bigrammi
#formatto il testo come bigrammi, poi separo le 2 parole per controllare se sono stop words, fig o hanno <= 2 lettere
#infine unisco di nuovo le 2 parole

books_bigrams <- normal_books %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  filter(!is.na(bigram)) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>%
  filter(word1 != "fig" & word2 != "fig") %>%
  filter(str_length(word1) > 2 & str_length(word2) > 2) %>%
  unite(bigram, word1, word2, sep = " ")

#top 10 bigrammi

books_bigrams %>%
  group_by(book) %>%
  count(bigram, sort=TRUE) %>%
  top_n(10, n) %>%
  ungroup() %>%
  mutate(bigram = reorder_within(bigram, n, book)) %>%
  ggplot(aes(bigram, n, fill = book)) +
  geom_col(show.legend = FALSE) +
  scale_x_reordered() +
  labs(y = "number of occurences") +
  facet_wrap(~book, scales = "free_y") +
  coord_flip()

```

## Analisi correlazione tra 2 libri

```{r, echo = FALSE}
freq_books <- books %>%
  filter(book == "the aincent life history of the earth" | book == "the chain of life in geological time") %>%
  group_by(book) %>%
  count(word, sort = TRUE) %>%
  mutate(proportion = n / sum(n)) %>%
  select(-n) %>%
  spread(book, proportion) %>%
  filter(!is.na(`the aincent life history of the earth`) & !is.na(`the chain of life in geological time`))

coeff <- cor.test(freq_books$`the aincent life history of the earth`, freq_books$`the chain of life in geological time`)
coeff <- str_extract(coeff$estimate, "\\d.\\d+")
```
Coefficiente di correlazione: `r as.double(coeff)` (`r as.integer(as.double(coeff)*100)`%)

```{r, echo = FALSE}  
freq_books %>%
  ggplot(aes(x = `the aincent life history of the earth`, y = `the chain of life in geological time`)) +
  geom_abline() +
  #geom_point(aes(label = word)) +
  geom_text(aes(label = word), check_overlap = TRUE) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format())
```


## Tf-idf dei libri

```{r, echo = FALSE}
#tf-idf dei libri

books_tfidf <- books %>%
  count(book, word, sort = TRUE) %>%
  bind_tf_idf(word, book, n)

books_tfidf %>%
  group_by(book) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, n, book)) %>%
  ggplot(aes(word, n, fill = book)) +
  geom_col(show.legend = FALSE) +
  scale_x_reordered() +
  labs(y = "number of occurences") +
  facet_wrap(~book, scales = "free_y") +
  coord_flip()

```

## Parole con valore di sentiment più alto (sia positivo che negativo)

```{r, echo = FALSE}
#parole che di più hanno contribuito al sentiment
#associo ad ogni parola un valore tra -5 e 5 che indica il grado di positività
#poi moltiplico questo numero per in numero di volte che quella parola viene ripetuta

afinn_books <- books %>%
  group_by(book) %>%
  count(word, sort = TRUE) %>%
  inner_join(get_sentiments("afinn")) %>%
  mutate(grade = value * n) %>%
  top_n(10, abs(grade)) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, grade, book))
  
afinn_books %>%
  ggplot(aes(word, grade, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, scales = "free_y") +
  labs(y = "number of occurences * value") +
  coord_flip() +
  scale_x_reordered()

```

## Variazione del sentiment per tutto il libro

```{r, echo = FALSE}
#come varia il sentiment per tutto il libro
#assegno un numero ad ogni riga 
#poi divido ogni libro in gruppi di 80 parole ed a ciascuno assegno un numero indice
#a questo punto per ogni indice calcolo il numero di parole positive - negative

indexed_books <- normal_books %>%
  group_by(book) %>%
  mutate(linenumber = row_number()) %>%
  ungroup() %>%
  unnest_tokens(word, text)

books_sentiment <- indexed_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

books_sentiment %>% ggplot(aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, scales = "free_x")

```

## Analizzo la seguente sezione del libro

```{r, echo = FALSE}
#evidenzio la parte di libro che voglio esaminare prendendo in considerazione solo alcuni indici

indexed_book1 <- book1 %>%
  mutate(linenumber = row_number()) %>%
  unnest_tokens(word, text) %>%
  mutate(index = linenumber %/% 80)

book1_sentiment <- indexed_book1 %>%
  inner_join(get_sentiments("bing")) %>%
  count(index, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

book1_sentiment %>% ggplot(aes(index, sentiment, fill = index > 53  & index < 62)) +
  scale_fill_manual(values=c("dark grey", "dark orange")) +
  geom_col(show.legend = FALSE)

```

## Parole più usate e con alto valore di sentiment

```{r, echo = FALSE}
#per prima cosa visualizzo le parole più usate negli indici che mi interessano
#poi sempre per quegli indici visualizzo le parole che hanno contribuito di più al sentiment

indexed_book1 <- indexed_book1 %>%
  filter(index > 53 & index < 62)

indexed_book1$gutenberg_id <- NULL

g1 <- indexed_book1 %>% 
  anti_join(stop_words) %>%
  mutate(word = wordStem(word)) %>%
  count(word, sort = TRUE) %>%
  top_n(15, n) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip()

g2 <- indexed_book1 %>%
  count(word, sort = TRUE) %>%
  inner_join(get_sentiments("afinn"))%>%
  mutate(grade = n * value) %>%
  top_n(15, abs(grade)) %>%
  mutate(word = reorder(word, grade)) %>%
  ggplot(aes(word, grade, fill = grade < 0)) +
  geom_col(show.legend = FALSE) +
  labs(y = "number of occurences * value") +
  labs(x = NULL) +
  coord_flip()

ggarrange(g1, g2, ncol = 2, nrow = 1)
```